================================================================================
SEARCH RESULTS FOR: NVIDIA
Date: December 17, 2025 at 04:33 PM
Total Articles: 7
================================================================================

ARTICLE 1
--------------------------------------------------------------------------------
URL: https://techcrunch.com/2025/11/19/nvidias-record-57b-revenue-and-upbeat-forecast-quiets-ai-bubble-talk/
--------------------------------------------------------------------------------
Nvidia founder and CEO Jensen Huang struck a bullish tone in the company’s third-quarter earnings. And based on the company’s results, there may be reason to.

Nvidiareportedrevenue of $57 billion in the third quarter, 62% higher compared to the same quarter last year. The company’s net income on a GAAP basis was $32 billion, 65% higher year-over-year. Both revenue and profit results beat Wall Street expectations.

The revenue picture shows a company booming thanks largely to its data center business. Revenue generated by Nvidia’s data center business was a record $51.2 billion, up 25% from the previous quarter and up 66% from a year ago. The remaining $5.8 billion in revenue came from Nvidia’s gaming business with $4.2 billion, followed by sales in professional visualization and automotive.

Nvidia’s CFO Colette Kressnoted in a statementto shareholders its data center business has been fueled by an acceleration of computing, powerful AI models, and agentic applications. During the company’s Q3 call, Kress said in this past quarter, the company announced AI factory and infrastructure projects amounting to an aggregate of 5 million GPUs.

“This demand spans every market, CSPs, sovereigns, modern builders enterprises and super computing centers, and includes multiple landmark build outs,” Kress said.

Blackwell Ultra, a GPU unveiled in March and available in several configurations, has been particularly strong and is now the leader within the company. Previous versions of the Blackwell architecture also saw continued strong demand, according to the company.

Huang said sales of its Blackwell GPU chips “are off the charts.”

“Blackwell sales are off the charts, and cloud GPUs are sold out,” Huang said in the company’s Q3 earnings statement. “Compute demand keeps accelerating and compounding across training and inference — each growing exponentially. We’ve entered the virtuous cycle of AI. The AI ecosystem is scaling fast — with more new foundation model makers, more AI startups, across more industries, and in more countries. AI is going everywhere, doing everything, all at once.”

Kress did note that the company’s shipments of H20, a data center GPU designed for generative AI and high-performance computing, were 50 million, a disappointing result due to its inability to sell to China.

“Sizable purchase orders never materialized in the quarter due to geopolitical issues and the increasingly competitive market in China,,” Kress noted on the earnings call. “While we were disappointed in the current state that prevents us from shipping more competitive data center compute products to China, we are committed to continued engagement with the U.S. and China governments, and will continue to advocate for America’s ability to compete around the world.”

Importantly, Nvidia is forecasting more growth with a projected revenue of $65 billion in the fourth quarter, helping push its share price up more than 4% in after-hours trading.

The upshot, at least in Huang’s view: forget about the bubble, there is only growth.

“There’s been a lot of talk about an AI bubble,” Jensen said during the company’s earnings call. “From our vantage point, we see something very different.”

================================================================================

ARTICLE 2
--------------------------------------------------------------------------------
URL: https://techcrunch.com/2025/12/10/nvidia-is-reportedly-testing-tracking-software-as-chip-smuggling-rumors-swirl/
--------------------------------------------------------------------------------
Nvidia is allegedly testing software that can track the location of its AI chips as reports of its chips being smuggled into China are on the rise.

Nvidia has built location verification technology that would allow it to track which country a chip is located in, Reutersoriginally reported, citing anonymous sources. This software tracks computing performance but the delay in communication between servers also offers a sense of a chip’s location.

This software will be optional for customers to use and will be made available for Blackwell chips first, Reuters said.

Multiple reports have surfaced in the last few days that allege China’s DeepSeek AI models have beentrained on smuggled Nvidia Blackwell chips. Nvidia responded to these reports by saying it hasn’t seen evidence of this type of smuggling.

“We haven’t seen any substantiation or received tips of ‘phantom data centers’ constructed to deceive us and our OEM partners, then deconstructed, smuggled, and reconstructed somewhere else. While such smuggling seems far-fetched, we pursue any tip we receive,” an Nvidia spokesperson told TechCrunch.

This news comes just days after Nvidia got the green light from the U.S. government to start selling itsH200 AI chips to approved customersin China on Monday. That announcement pertains only to older H200 chips and not the company’s Blackwell chips.

================================================================================

ARTICLE 3
--------------------------------------------------------------------------------
URL: https://techcrunch.com/2025/09/15/china-says-nvidia-violated-antitrust-regulations/
--------------------------------------------------------------------------------
Trade tensions between China and the U.S. regarding semiconductors just got even more strained.

On Monday, China’s State Administration for Market Regulation ruled that semiconductor giant Nvidia was in violation of the country’s antitrust regulations, asfirst reported by Bloomberg. The ruling was in reference toNvidia’s 2020 acquisition ofMellanox Technologies, a computer networking supplier, for $7 billion.

An Nvidia spokesperson supplied the following statement: “We comply with the law in all respects. We will continue to cooperate with all relevant government agencies as they evaluate the impact of export controls on competition in the commercial markets.”

China didn’t announce any consequences tied to its findings and will continue to investigate. Still, the ruling is likely to cast a pall over ongoing tariff negotiations between the U.S. and China, currently taking place in Madrid. While these trade discussions aren’t specifically about semiconductors, the question of Chinese access to Nvidia chips is a major point of contention between the two regimes.

The outgoing Biden administration announced itsAI Diffusion Ruleback in January that was meant to restrict U.S.-made AI chips to many countries, with further restrictions specifically for China and other adversaries.

While the U.S. Department of Commerceformally repealed Biden’s AI rule in May, the future of AI chip exports to China remains in flux. The Trump administration slappedlicensing agreementson chips heading to China in April. A few months later, in July, these companies weregiven the green lightto start selling these chips again.

Just a few weeks after that the country struck a deal requiring companies selling chips to China to give the U.S. a15% cut of the revenuemade on those sales. China has discouraged firms frombuying Nvidia chipsand, as ofa recent earnings call, none of the company’s chips have made it through the new export process.

================================================================================

ARTICLE 4
--------------------------------------------------------------------------------
URL: https://techcrunch.com/2025/08/27/nvidia-reports-record-sales-as-the-ai-boom-continues/
--------------------------------------------------------------------------------
Nvidia, the world’s most valuable company, reported another quarter of sustained sales growth in its earnings statement Wednesday, with $46.7 billion in revenue, a 56% increase compared to the same period last year. That growth was largely fueled by AI-dominated data center business, which saw a 56% year-over-year increase in revenue.

Nvidia also saw its net income grow substantially since last year. The company reported a net income of $26.4 billion in the second quarter, a 59% spike since the same period last year.

All told, the company brought in $41.1 billion in revenue from data center sales in the quarter, suggesting that AI companies’ demand for cutting-edge GPUs continues to grow. The company’s most advanced generation of chips, Blackwell, accounted for $27 billion of those sales.

“Blackwell is the AI platform the world has been waiting for,” said CEO Jensen Huang in a statement accompanying the release. “The AI race is on, and Blackwell is the platform at its center.”

Huang said that the company expects to see $3 to 4 trillion in AI infrastructure spending by the end of the decade. “$3 to 4 trillion is fairly sensible for the next five years,” he told one analyst.

The company made particular note of its role in the launch ofOpenAI’s open source gpt-oss modelsearlier this month, which involved processing “1.5 million tokens per second on a single Nvidia Blackwell GB200 NVL72 rack-scale system.”

The earnings also gave a look at Nvidia’s ongoing struggle to sell its chips in Chinese markets. The company reported no sales of its China-focused H20 chip to Chinese customers in the past quarter; Nvidia did report $650 million worth of H20 chips had been sold to a customer outside China.

The United States has long restricted sales of advanced GPUs to Chinese customers — but the geopolitical situation has changed significantly under President Trump. The company is now permitted to sell chips to China as long as it pays a 15% export tax to the U.S. Treasury, as a result of an unconventional arrangement that legal scholars have described asan unconstitutional abuse of power.

On the earnings call, Nvidia CFO Colette Kress made clear that the lack of shipment was a result of uncertainty around the arrangement, which has not been officially codified into a federal regulation. “While a select number of our China-based customers have received licenses over the past few weeks,” Kress said, “we have not shipped any H20 devices based on those licenses.”

Still, the Chinese government hasofficially discouragedthe use of Nvidia chips by local businesses, leading the company toreportedly halt productionof the H20 chip earlier this month.

Nvidia said it expects $54 billion in revenue in the third quarter. The company noted that its outlook for the third quarter, which could shift 2% in either direction, doesn’t include any H20 shipments to China.

================================================================================

ARTICLE 5
--------------------------------------------------------------------------------
URL: https://techcrunch.com/2025/09/24/alibaba-to-offer-nvidias-physical-ai-development-tools-in-its-ai-platform/
--------------------------------------------------------------------------------
Nvidia is on a dealmaking spree: Days after committing totaking a $5 billion stake in Inteland a whopping$100 billion investment in OpenAI, the GPU maker has now struck a partnership with China’s Alibaba.

Alibabasaidon Wednesday that it is integrating Nvidia’s AI development tools for robotics, self-driving cars, and connected spaces into its Cloud Platform for AI. The Chinese e-commerce giant will offer Nvidia’s Physical AI software stack, which can construct 3D replicas of real-world environments to generate synthetic data with which AI models can be trained for robotics, self-driving vehicles, or smart spaces like factories and warehouses.

Financial terms of the deal were not disclosed, but this marks a significant collaboration, as it brings together the world’s foremost developer of chips optimized for training AI models, and a major cloud services and AI model developer.

The deal comes as Alibaba focuses on building out its AI business further alongside its main e-commerce business. The company said on Wednesday that it is ramping up spending on AI tech past its previous $50 billion budget, and outlined plans to launch its first data centers in Brazil, France, and the Netherlands. It is also building more data centers in more countries, expanding its data center presence at 91 locations in 29 regions around the world.

Alibaba on Wednesday also unveiled the latest iteration of its Qwen family of large language models,Qwen 3-Max. The company claims the model is its “largest and most capable model to date,” trained on 1 trillion parameters, and that it is well-suited for coding and agentic use.

================================================================================

ARTICLE 6
--------------------------------------------------------------------------------
URL: https://techcrunch.com/2025/12/03/andy-jassy-says-amazons-nvidia-competitor-chip-is-already-a-multi-billion-dollar-business/
--------------------------------------------------------------------------------
Can any company, big or small, really topple Nvidia’s AI chip dominance? Maybe not. But there are hundreds of billions of dollars of revenue for those who can even peel off a chunk of it for themselves, Amazon CEO Andy Jassy said this week.

As expected, the company revealed at the AWS re:Invent conference the next generation of its Nvidia-competitor AI chip, Trainium3, which is 4x faster yet uses less power than the current Trainium2. Jassy revealed a few tidbits about the current Trainiumin a post on Xthat shows why the company is so bullish on the chip.

He said the Trainium2 business “has substantial traction, is a multi-billion-dollar revenue run-rate business, has 1M+ chips in production, and 100K+ companies using it as the majority of Bedrock usage today.”

Bedrock is Amazon’s AI app development tool that allows companies to pick and choose among many AI models.

Jassy said Amazon’s AI chip is winning among the company’s enormous roster of cloud customers because it “has price-performance advantages over other GPU options that are compelling.” In other words, he believes it works better and costs less than those “other GPUs” out there on the market.

That is, of course, Amazon’sclassic MO, offering its own homegrown tech at lower prices.

Additionally, AWS CEO Matt Garman offered even more insight in aninterview with CRN, about one customer responsible for a big chunk of those billions in revenue: No shock here, it’s Anthropic.

“We’ve seen some enormous traction from Trainium2, particularly from our partners at Anthropic who we’ve announced Project Rainier, where there’s over 500,000 Trainium2 chips helping them build the next generations of models for Claude,” Garman said.

Project Rainier is Amazon’s most ambitious AI cluster of servers, spread across multiple data centers in the U.S. and built to serve Anthropic’s skyrocketing needs. It cameonline in October. Amazon is, of course, amajor investor in Anthropic. In exchange, Anthropic made AWS its primary model training partner, even though Anthropic is now also offered on Microsoft’s cloudvia Nvidia’s chips.

OpenAI is now also using AWS in addition to Microsoft’s cloud. But the OpenAI partnership couldn’t have contributed much to Trainium’s revenue because AWS is running it on Nvidia chips and systems,the cloud giant said.

Indeed, only a few U.S. companies like Google, Microsoft, Amazon, and Meta have all the engineering pieces — silicon chip design expertise, homegrown high-speed interconnect. and networking technology — to even attempt true competition with Nvidia. (Remember, Nvidia cornered the market on one major high-performance networking tech in 2019 when CEO Jensen Huang outbidIntel and Microsoft to buy InfiniBand hardware maker Mellanox.)

On top of that, AI models and software built to be served up by Nvidia’s chips also rely on Nvidia’s proprietary Compute Unified Device Architecture (CUDA) software. CUDA allows the apps to use the GPUs for parallel processing compute, among other tasks. Just like the Intel versus SPARC chip war of yesterday, it’s no small thing torewrite an AI app for a non-CUDA chip.

Still, Amazon may have a plan for that. As we previously reported, the next generation of its AI chip, Trainium4, will be built to interoperate with Nvidia’s GPUs in the same system. Whether that helps peel more business away from Nvidia or simply reinforces its dominance, but on AWS’s cloud, remains to be seen.

It may not matter to Amazon. If it is already on track to make multibillion dollars from the Trainium2 chip, and the next generation will be that much better, it may be winner enough.

================================================================================

ARTICLE 7
--------------------------------------------------------------------------------
URL: https://techcrunch.com/2025/08/12/how-a-once-tiny-research-lab-helped-nvidia-become-a-4-trillion-dollar-company/
--------------------------------------------------------------------------------
When Bill Dally joined Nvidia’s research lab in 2009, it employed only about a dozen people and was focused on ray tracing, a rendering technique used in computer graphics.

That once-small research lab now employs more than 400 people, who have helped transform Nvidia from a video game GPU startup in the nineties to a $4 trillion-dollar company fueling the artificial intelligence boom.Now, the company’s research lab has its sights set on developing the tech needed to power robotics and AI. And some of that lab work is already showing up in products. The company unveiled Monday anew set of world AI models, libraries, and other infrastructure for robotics developers.

Dally, now Nvidia’s chief scientist, started consulting for Nvidia in 2003 while he was working at Stanford. When he was ready to step down from being the department chair of Stanford’s computer science department a few years later, he planned to take a sabbatical. Nvidia had a different idea.

David Kirk, who was running the research lab at the time, and Nvidia CEO Jensen Huang, thought a more permanent position at the research lab was a better idea. Dally told TechCrunch the pair put on a “full-court press” on why he should join Nvidia’s research lab and eventually convinced him.

“It wound up being kind of a perfect fit for my interests and my talents,” Dally said. “I think everybody’s always searching for the place in life where they can make the biggest contribution to the world. And I think for me, it’s definitely Nvidia.”

When Dally took over the lab in 2009, expansion was first and foremost. Researchers started working on areas outside of ray tracing right away, including circuit design and VLSI, or very large-scale integration, a process that combines millions of transistors on a single chip.

The research lab hasn’t stopped expanding since.

“We try to figure out what will make the most positive difference for the company because we’re constantly seeing exciting new areas, but some of them, they do great work, but we have trouble saying if [we’ll be] wildly successful at this,” Dally said.

For a while that was building better GPUs for artificial intelligence. Nvidia was early to the future AI boom and started tinkering with the idea of AI GPUs in 2010 — more than a decade before the current AI frenzy.

“We said this is amazing, this is gonna completely change the world,” Dally said. “We have to start doubling down on this and Jensen believed that when I told him that. We started specializing our GPUs for it and developing lots of software to support it, engaging with the researchers all around the world who were doing it, long before it was clearly relevant.”

Now, as Nvidia holds a commanding lead in the AI GPU market, the tech company has started to seek out new areas of demand beyond AI data centers. That search has led Nvidia to physical AI and robotics.

“I think eventually robots are going to be a huge player in the world and we want to basically be making the brains of all the robots,” Dally said. “To do that we need to start developing the key technologies.”

That’s where Sanja Fidler, the vice president of AI research at Nvidia, comes in. Fidler joined Nvidia’s research lab in 2018. At the time, she was already working on simulation models for robots with a team of students at MIT. When she told Huang about what they were working on at a researchers’ reception, he was interested.

“I could not resist joining,” Fidler told TechCrunch in an interview. “It’s just such a great topic fit and at the same time was also such a great culture fit. Jensen told me, come work with me, not with us, not for us.”

She joined Nvidia and got to work creating a research lab in Toronto called Omniverse, an Nvidia platform, that was focused on building simulations for physical AI.

The first challenge to building these simulated worlds was finding the necessary 3D data, Fidler said. This included finding the proper volume of potential images to use and building the technology needed to turn these images into 3D renditions the simulators could use.

“We invested in this technology called differentiable rendering, which essentially makes rendering amendable to AI,” Fidler said. “You go [from] rendering means from 3D to image or video. And we want it to go the other way.”

Omniverse released the first version of its model that turns images into 3D models,GANverse3D, in 2021. Then it got to work on figuring out the same process for video. Fidler said they used videos from robots and self-driving cars to create these 3D models and simulations through itsNeural Reconstruction Engine, which the company first announced in 2022.

She added these technologies were the backbone of the company’sCosmos family of world AI modelsthat were announced at CES in January.

Now, the lab is focused on making these models faster. When you play a video game or simulation you want the tech to be able to respond in real time, Fidler said, for robots they are working to make the reaction time even faster.

“The robot doesn’t need to watch the world in the same time, in the same way as the world works,” Fidler said. “It can watch it like 100x faster. So if we can make this model significantly faster than they are today, they’re going to be tremendously useful for robotic or physical AI applications.”

The company continues to make progress on this goal. Nvidia announced at the SIGGRAPH computer graphics conference on Monday a fleet ofnew world AI modelsdesigned for creating synthetic data that can be used to train robots. Nvidia also announced new libraries and infrastructure software aimed at robotics developers too.

Despite the progress — and the current hype about robots, especially humanoids — the Nvidia research team remains realistic.

Both Dally and Fidler said the industry is still at least a few years off from having a humanoid in your home, with Fidler comparing it to the hype and timeline regarding autonomous vehicles.

“We’re making huge progress and I think AI has really been the enabler here,” Dally said. “Starting with visual AI for the robot perception, and then generative AI, that’s being hugely valuable for task and motion planning and manipulation. As we solve each of these individual little problems and as the amount of data we have to train our networks grows, these robots are going to grow.”

We’re always looking to evolve, and by providing some insight into your perspective and feedback into TechCrunch and our coverage and events, you can help us! Fill outthis surveyto let us know how we’re doing and get the chance to win a prize in return!

================================================================================

